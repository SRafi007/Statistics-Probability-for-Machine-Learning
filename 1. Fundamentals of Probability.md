# Lesson 1: Fundamentals of Probability

## Introduction

Probability theory provides the mathematical foundation for handling uncertainty, which is central to machine learning. This lesson introduces the core concepts of probability that you'll need throughout this course.

## 1. What is Probability?

Probability measures the likelihood of an event occurring. Mathematically, it's defined as:

$$P(E) = \frac{\text{Number of favorable outcomes}}{\text{Total number of possible outcomes}}$$

Probability values range from 0 (impossible event) to 1 (certain event).

### Example: Rolling a Die

When rolling a standard 6-sided die, the probability of rolling a 3 is:

$$P(3) = \frac{1}{6} = 0.1667 \text{ (or 16.67\%)}$$

```
Die Roll Probability Distribution:
  0.16 |   *   *   *   *   *   * 
  0.14 |   |   |   |   |   |   |
  0.12 |   |   |   |   |   |   |
  0.10 |   |   |   |   |   |   |
  0.08 |   |   |   |   |   |   |
  0.06 |   |   |   |   |   |   |
  0.04 |   |   |   |   |   |   |
  0.02 |   |   |   |   |   |   |
  0.00 +---+---+---+---+---+---+
        1   2   3   4   5   6
         Outcome (number on die)
```

*This uniform distribution shows that each outcome (1-6) has an equal probability of 1/6.*

## 2. Sample Space & Events

- **Sample Space (S)**: The complete set of all possible outcomes of a random experiment.
- **Event (E)**: A subset of the sample space, representing a particular outcome or set of outcomes.

### Example: Drawing from a Deck of Cards

- The sample space (S) consists of all 52 cards.
- If event E = "drawing a red card", then E contains 26 cards (13 hearts + 13 diamonds).
- Therefore, P(E) = 26/52 = 0.5 or 50%.

```
Card Deck Probability:
              Hearts
            ┌───────┐
            │ 25%   │
    Spades  │       │  Diamonds
  ┌───────┐ │       │ ┌───────┐
  │ 25%   │ └───────┘ │ 25%   │
  │       │    Red     │       │
  │       │  (50%)    │       │
  └───────┘           └───────┘
   Black             ┌───────┐
   (50%)             │ 25%   │
                     │       │
                     └───────┘
                       Clubs
```

*This diagram shows the probability distribution of drawing different suits from a standard deck.*

## 3. Types of Probability

### a) Theoretical Probability
Based on logical reasoning without conducting experiments.

**Example**: The probability of getting heads in a fair coin toss is 1/2 = 50%.

### b) Experimental Probability
Based on observations from repeated trials of an experiment.

**Example**: If we flip a coin 100 times and get heads 48 times:

$$P(H) = \frac{48}{100} = 0.48 \text{ (or 48\%)}$$

```
Experimental vs Theoretical Probability (Coin Flips):
  1.0 |                            - - - - - - - - - -
      |                        ----
  0.8 |                    ----
      |                ----
P(H)  |            ----
  0.6 |        ----
      |    ----
  0.4 |----
      |
  0.2 |
      |
  0.0 +----+----+----+----+----+----+----+----+
      0   10   20   50  100  200  500 1000 5000
           Number of coin flips (log scale)

  — Experimental probability  - - Theoretical probability (0.5)
```

*This graph shows how experimental probability converges to theoretical probability as the number of trials increases.*

### c) Subjective Probability
Based on personal judgment, prior knowledge, or belief.

**Example**: A weather forecast states a 70% chance of rain tomorrow.

## 4. Basic Probability Rules

### a) Rule of Complement
The probability that an event doesn't occur equals 1 minus the probability that it does occur:

$$P(\text{not }E) = 1 - P(E)$$

**Example**: If P(rain) = 0.7, then P(no rain) = 1 - 0.7 = 0.3.

```
Complement Rule Visualization:
  ┌────────────────────────────────────┐
  │                                    │
  │    ┌────────────────┐              │
  │    │     P(E)       │  P(not E)    │
  │    │     0.7        │    0.3       │
  │    └────────────────┘              │
  │                                    │
  └────────────────────────────────────┘
         Sample Space (Total = 1)
```

*Visual representation of the complement rule showing that P(E) + P(not E) = 1.*

### b) Addition Rule (for OR events)
For mutually exclusive events (cannot occur simultaneously):

$$P(A \text{ OR } B) = P(A) + P(B)$$

**Example**: Probability of rolling a 1 or a 2 on a die:

$$P(1) + P(2) = \frac{1}{6} + \frac{1}{6} = \frac{2}{6} = 0.333 \text{ (or 33.3\%)}$$

For non-mutually exclusive events (can occur simultaneously):

$$P(A \text{ OR } B) = P(A) + P(B) - P(A \text{ AND } B)$$

**Example**: Probability of drawing a king or a heart:

$$P(\text{King OR Heart}) = P(\text{King}) + P(\text{Heart}) - P(\text{King AND Heart})$$
$$= \frac{4}{52} + \frac{13}{52} - \frac{1}{52} = \frac{16}{52} = 0.308 \text{ (or 30.8\%)}$$

```
Venn Diagram for Addition Rule:

   Mutually Exclusive Events    |    Non-Mutually Exclusive Events
                                |
   ┌───────┐     ┌───────┐     |     ┌───────┬───────┐
   │       │     │       │     |     │       │       │
   │   A   │     │   B   │     |     │   A   │   B   │
   │       │     │       │     |     │       │       │
   └───────┘     └───────┘     |     └───────┴───────┘
                                |
   P(A OR B) = P(A) + P(B)      |   P(A OR B) = P(A) + P(B) - P(A AND B)
```

*Venn diagram illustrating the addition rule for both mutually exclusive and non-mutually exclusive events.*

### c) Multiplication Rule (for AND events)
For independent events (occurrence of one doesn't affect the other):

$$P(A \text{ AND } B) = P(A) \times P(B)$$

**Example**: Probability of flipping two heads in a row:

$$P(H) \times P(H) = \frac{1}{2} \times \frac{1}{2} = \frac{1}{4} = 0.25 \text{ (or 25\%)}$$

For dependent events:

$$P(A \text{ AND } B) = P(A) \times P(B|A)$$

**Example**: Probability of drawing two aces in succession without replacement:

$$P(\text{Ace 1st AND Ace 2nd}) = P(\text{Ace 1st}) \times P(\text{Ace 2nd | Ace 1st})$$
$$= \frac{4}{52} \times \frac{3}{51} = \frac{12}{2652} = 0.0045 \text{ (or 0.45\%)}$$

```
Tree Diagram for Multiplication Rule (Two Coin Flips):

                 ┌── Heads (H) ── P(H,H) = 1/4
                 │   P = 1/2
     Heads (H) ──┤
     P = 1/2     │
                 └── Tails (T) ── P(H,T) = 1/4
                     P = 1/2
First Flip        
                 ┌── Heads (H) ── P(T,H) = 1/4
                 │   P = 1/2
     Tails (T) ──┤
     P = 1/2     │
                 └── Tails (T) ── P(T,T) = 1/4
                     P = 1/2
                      Second Flip
```

*Tree diagram showing the multiplication rule for calculating compound probabilities.*

## 5. Conditional Probability & Bayes' Theorem

### Conditional Probability
The probability of event A occurring given that event B has already occurred:

$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

**Example**: In a class of 60 students, 40 are boys, and 10 boys play football. If we select a student and know they are a boy, the probability that they play football is:

$$P(\text{Football | Boy}) = \frac{10}{40} = 0.25 \text{ (or 25\%)}$$

```
Conditional Probability Visualization:

  All Students (60)
  ┌───────────────────────────────────┐
  │                                   │
  │  Boys (40)                        │
  │  ┌─────────────────────┐ Girls(20)│
  │  │                     │          │
  │  │  Football (10)      │          │
  │  │  ┌─────────┐        │          │
  │  │  │         │        │          │
  │  │  │         │        │          │
  │  │  └─────────┘        │          │
  │  │                     │          │
  │  └─────────────────────┘          │
  │                                   │
  └───────────────────────────────────┘
  
  P(Football | Boy) = 10/40 = 0.25
```

*Visual representation showing how conditional probability restricts the sample space.*

### Bayes' Theorem
Allows updating probabilities based on new evidence:

$$P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$$

**Example**: Medical Testing
- 1% of the population has a certain disease (P(D) = 0.01)
- A test for this disease is 95% accurate (P(Positive|D) = 0.95)
- The false positive rate is 10% (P(Positive|not D) = 0.1)

What's the probability a person has the disease given they tested positive?

$$P(D|\text{Positive}) = \frac{P(\text{Positive}|D) \times P(D)}{P(\text{Positive})}$$

$$P(\text{Positive}) = P(\text{Positive}|D) \times P(D) + P(\text{Positive}|\text{not D}) \times P(\text{not D})$$
$$= 0.95 \times 0.01 + 0.1 \times 0.99 = 0.0095 + 0.099 = 0.1085$$

$$P(D|\text{Positive}) = \frac{0.95 \times 0.01}{0.1085} = \frac{0.0095}{0.1085} \approx 0.0876 \text{ (or 8.76\%)}$$

```
Bayes' Theorem Medical Test Visualization:

  Population (10,000 people)
  ┌────────────────────────────────────────────────┐
  │                                                │
  │ Disease (100)         No Disease (9,900)       │
  │ ┌──────────┐          ┌───────────────────┐    │
  │ │          │          │                   │    │
  │ │  Test+   │          │     Test+         │    │
  │ │  (95)    │          │     (990)         │    │
  │ │          │          │                   │    │
  │ └──────────┘          └───────────────────┘    │
  │ ┌──────────┐          ┌───────────────────┐    │
  │ │  Test-   │          │     Test-         │    │
  │ │   (5)    │          │    (8,910)        │    │
  │ │          │          │                   │    │
  │ └──────────┘          └───────────────────┘    │
  │                                                │
  └────────────────────────────────────────────────┘
  
  P(Disease | Test+) = 95 / (95 + 990) ≈ 8.76%
```

*Visualization of how Bayes' theorem updates our belief about having a disease after receiving a positive test result.*

## 6. Important Probability Distributions in ML

### Bernoulli Distribution
Models a single binary outcome (success/failure) with probability *p*.

$$P(X=1) = p \quad \text{and} \quad P(X=0) = 1-p$$

**Example**: A single coin flip (Heads=1, Tails=0)

```
Bernoulli Distribution (p=0.6):
  0.6 |          *
      |          |
  0.5 |          |
      |          |
P(X)  |          |
  0.4 |          |
      |          |
  0.3 |          |          *
      |          |          |
  0.2 |          |          |
      |          |          |
  0.1 |          |          |
      |          |          |
  0.0 +----------+----------+
              0          1
                  X
```

*Bar chart showing the probability mass function for a Bernoulli random variable with p=0.6.*

### Binomial Distribution
Models the number of successes in *n* independent Bernoulli trials.

$$P(X=k) = \binom{n}{k} p^k (1-p)^{n-k}$$

**Example**: Number of heads in 10 coin flips.

```
Binomial Distribution (n=10, p=0.5):
  0.25 |                *
       |                |
  0.20 |             *  |  *
       |             |  |  |
P(X=k) |          *  |  |  |  *
  0.15 |          |  |  |  |  |
       |       *  |  |  |  |  |  *
  0.10 |       |  |  |  |  |  |  |
       |    *  |  |  |  |  |  |  |  *
  0.05 |    |  |  |  |  |  |  |  |  |
       | *  |  |  |  |  |  |  |  |  |  *
  0.00 +-+--+--+--+--+--+--+--+--+--+--+
        0  1  2  3  4  5  6  7  8  9  10
               Number of successes (k)
```

*Probability mass function for a binomial distribution with n=10 and p=0.5.*

### Poisson Distribution
Models the number of events occurring in a fixed interval, when events happen at a constant average rate.

$$P(X=k) = \frac{\lambda^k e^{-\lambda}}{k!}$$

**Example**: Number of customers arriving at a store per hour.

```
Poisson Distributions with Different λ Values:
  0.4 |
      |    *
  0.3 |    |
      |    |     *
P(X=k)|    |     |
  0.2 |    |  *  | *
      |    |  |  | |  *
  0.1 | *  |  |  | |  | *  *
      | |  |  |  | |  | |  | *  *  *  *
  0.0 +-+--+--+--+--+--+--+--+--+--+--+
       0  1  2  3  4  5  6  7  8  9  10
              Number of events (k)

  — λ=1    --- λ=3    ··· λ=5
```

*Probability mass functions for Poisson distributions with different λ values.*

### Normal (Gaussian) Distribution
Continuous probability distribution defined by mean (μ) and standard deviation (σ).

$$f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$$

**Example**: Heights of adult humans, IQ scores, measurement errors.

```
Normal Distributions:
                  ╱|╲
                 ╱ | ╲
                ╱  |  ╲
               ╱   |   ╲
              ╱    |    ╲
        _ _ _╱     |     ╲_ _ _
      ╱      |     |     |      ╲
     ╱       |     |     |       ╲
 ___╱        |     |     |        ╲___
    -3σ    -1σ     μ    +1σ      +3σ
    
  — μ=0, σ=1 (Standard Normal)
  --- μ=2, σ=0.5 (Narrower, shifted right)
  ... μ=-1, σ=2 (Wider, shifted left)
```

*Bell curves showing normal distributions with different μ and σ parameters.*

## 7. Real-World Applications in Machine Learning

### Spam Filtering
Bayes' theorem helps classify emails by calculating the probability that an email is spam given certain words appear in it.

### Risk Prediction
Financial institutions use probability models to estimate loan default risks based on various customer attributes.

### Medical Diagnosis
Conditional probability helps doctors calculate the likelihood of different diseases given observed symptoms.

### Natural Language Processing
Word prediction models use probability distributions to predict the next word in a sentence.

### Reinforcement Learning
Probability theory helps agents make decisions under uncertainty when learning optimal strategies.

## 8. Quick Recap
- Probability quantifies uncertainty on a scale from 0 (impossible) to 1 (certain)
- Basic probability rules: complement, addition (OR), multiplication (AND)
- Conditional probability calculates the likelihood of an event given another event
- Bayes' theorem updates probabilities based on new evidence
- Probability distributions (Bernoulli, Binomial, Poisson, Normal) model different random phenomena
- Machine learning applications heavily rely on probability theory for decision-making under uncertainty

## Quiz: Fundamentals of Probability

1. What is the probability of rolling an even number on a standard 6-sided die?
   a) 1/6
   b) 1/3
   c) 1/2
   d) 2/3

2. If you draw a card from a standard deck, what is the probability of drawing a face card (Jack, Queen, or King)?
   a) 3/13
   b) 12/52
   c) 1/4
   d) All of the above

3. Two coins are flipped. What is the probability of getting at least one head?
   a) 1/4
   b) 1/2
   c) 3/4
   d) 1

4. In a city, 60% of days are sunny. If it's sunny, the probability of going to the beach is 80%. What is the probability that it's sunny and you go to the beach?
   a) 28%
   b) 48%
   c) 60%
   d) 80%

5. A bag contains 5 red marbles and 3 blue marbles. If you draw 2 marbles without replacement, what is the probability that both are red?
   a) 5/16
   b) 5/8
   c) 5/14
   d) 10/28

6. Which of the following is NOT a valid probability value?
   a) 0
   b) 0.5
   c) 1
   d) 1.5

7. In a Bernoulli distribution with p = 0.7, what is the probability of failure?
   a) 0.3
   b) 0.7
   c) 0
   d) 1

8. The normal distribution is completely defined by which two parameters?
   a) Mean and mode
   b) Mean and median
   c) Mean and standard deviation
   d) Median and standard deviation

9. If events A and B are independent, which of the following is true?
   a) P(A|B) = P(A)
   b) P(A and B) = P(A) + P(B)
   c) P(A or B) = P(A) × P(B)
   d) P(A) = P(B)

10. A medical test is 95% accurate for detecting a disease when it's present, and 90% accurate for correctly identifying healthy individuals. If 2% of the population has the disease, what's the probability that a person with a positive test result actually has the disease?
    a) About 16%
    b) About 95%
    c) About 2%
    d) About 90%

## Quiz Answers:

1. c) 1/2
   *Explanation: Even numbers on a die are 2, 4, and 6. So P(even) = 3/6 = 1/2.*

2. d) All of the above
   *Explanation: There are 12 face cards in a 52-card deck. Therefore, P(face card) = 12/52 = 3/13 = 1/4.*

3. c) 3/4
   *Explanation: P(at least one head) = 1 - P(no heads) = 1 - P(tail, tail) = 1 - (1/2 × 1/2) = 1 - 1/4 = 3/4.*

4. b) 48%
   *Explanation: Using the multiplication rule for AND events: P(sunny AND beach) = P(sunny) × P(beach|sunny) = 0.6 × 0.8 = 0.48 = 48%.*

5. c) 5/14
   *Explanation: Using the formula for dependent events: P(1st red AND 2nd red) = P(1st red) × P(2nd red|1st red) = 5/8 × 4/7 = 20/56 = 5/14.*

6. d) 1.5
   *Explanation: Valid probability values must be between 0 and 1 inclusive.*

7. a) 0.3
   *Explanation: In a Bernoulli distribution, P(failure) = 1 - P(success) = 1 - 0.7 = 0.3.*

8. c) Mean and standard deviation
   *Explanation: A normal distribution is completely characterized by its mean (μ) and standard deviation (σ).*

9. a) P(A|B) = P(A)
   *Explanation: By definition, if A and B are independent, the occurrence of B doesn't affect the probability of A.*

10. a) About 16%
    *Explanation: Using Bayes' theorem:
    P(D|+) = [P(+|D) × P(D)] / [P(+|D) × P(D) + P(+|not D) × P(not D)]
    = [0.95 × 0.02] / [0.95 × 0.02 + 0.1 × 0.98]
    = 0.019 / (0.019 + 0.098) = 0.019 / 0.117 ≈ 0.16 or about 16%.*
